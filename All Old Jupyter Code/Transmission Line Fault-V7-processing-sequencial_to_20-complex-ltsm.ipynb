{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea19e76-ed3d-4281-b93e-bf030a19c6c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN values found in testing_data_trial_2\\04_04_2023_17_18_15_4349.csv.\n",
      "All values are NaN in testing_data_trial_2\\04_04_2023_17_18_15_4349.csv. Skipping this file.\n",
      "NaN values found in testing_data_trial_2\\06_07_2023_13_03_06_10047.csv.\n",
      "All values are NaN in testing_data_trial_2\\06_07_2023_13_03_06_10047.csv. Skipping this file.\n",
      "NaN values found in testing_data_trial_2\\07_09_2023_18_10_24_12842.csv.\n",
      "All values are NaN in testing_data_trial_2\\07_09_2023_18_10_24_12842.csv. Skipping this file.\n",
      "NaN values found in testing_data_trial_2\\08_10_2023_10_13_58_14447.csv.\n",
      "All values are NaN in testing_data_trial_2\\08_10_2023_10_13_58_14447.csv. Skipping this file.\n",
      "NaN values found in testing_data_trial_2\\08_10_2023_10_48_23_14449.csv.\n",
      "All values are NaN in testing_data_trial_2\\08_10_2023_10_48_23_14449.csv. Skipping this file.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\College\\7th Semester\\Internship\\Application\\venv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m73249/73249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1099s\u001b[0m 15ms/step - loss: 0.0098\n",
      "Epoch 2/20\n",
      "\u001b[1m73249/73249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1014s\u001b[0m 14ms/step - loss: 0.0084\n",
      "Epoch 3/20\n",
      "\u001b[1m73249/73249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1686s\u001b[0m 23ms/step - loss: 0.0084\n",
      "Epoch 4/20\n",
      "\u001b[1m73249/73249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1066s\u001b[0m 15ms/step - loss: 0.0084\n",
      "Epoch 5/20\n",
      "\u001b[1m73249/73249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1071s\u001b[0m 15ms/step - loss: 0.0083\n",
      "Epoch 6/20\n",
      "\u001b[1m73249/73249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1973s\u001b[0m 27ms/step - loss: 0.0083\n",
      "Epoch 7/20\n",
      "\u001b[1m73249/73249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1180s\u001b[0m 16ms/step - loss: 0.0084\n",
      "Epoch 8/20\n",
      "\u001b[1m73249/73249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1061s\u001b[0m 14ms/step - loss: 0.0083\n",
      "Epoch 9/20\n",
      "\u001b[1m73249/73249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1155s\u001b[0m 16ms/step - loss: 0.0083\n",
      "Epoch 10/20\n",
      "\u001b[1m73249/73249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1501s\u001b[0m 20ms/step - loss: 0.0083\n",
      "Epoch 11/20\n",
      "\u001b[1m73249/73249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1452s\u001b[0m 20ms/step - loss: 0.0084\n",
      "Epoch 12/20\n",
      "\u001b[1m73249/73249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1434s\u001b[0m 20ms/step - loss: 0.0083\n",
      "Epoch 13/20\n",
      "\u001b[1m73249/73249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1152s\u001b[0m 16ms/step - loss: 0.0083\n",
      "Epoch 14/20\n",
      "\u001b[1m73249/73249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6111s\u001b[0m 83ms/step - loss: 0.0083\n",
      "Epoch 15/20\n",
      "\u001b[1m73249/73249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1079s\u001b[0m 15ms/step - loss: 0.0083\n",
      "Epoch 16/20\n",
      "\u001b[1m73249/73249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1306s\u001b[0m 18ms/step - loss: 0.0083\n",
      "Epoch 17/20\n",
      "\u001b[1m73249/73249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1123s\u001b[0m 15ms/step - loss: 0.0083\n",
      "Epoch 18/20\n",
      "\u001b[1m73249/73249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1056s\u001b[0m 14ms/step - loss: 0.0083\n",
      "Epoch 19/20\n",
      "\u001b[1m73249/73249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1143s\u001b[0m 16ms/step - loss: 0.0083\n",
      "Epoch 20/20\n",
      "\u001b[1m73249/73249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1276s\u001b[0m 17ms/step - loss: 0.0083\n",
      "\u001b[1m67412/73249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m26s\u001b[0m 5ms/step"
     ]
    }
   ],
   "source": [
    "# Added more layers in LTSM Models for Good Results with Dense etc.,\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras._tf_keras.keras.models import Sequential \n",
    "from keras._tf_keras.keras.layers import Dense, LSTM, Dropout\n",
    "\n",
    "def preprocess_csv(file_path):\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        vrm_data = df['VRM'].values.reshape(-1, 1)\n",
    "        \n",
    "        # Check for NaN values\n",
    "        if np.any(np.isnan(vrm_data)):\n",
    "            print(f\"NaN values found in {file_path}.\")\n",
    "            # Check if there are any valid values to compute the mean\n",
    "            if np.count_nonzero(~np.isnan(vrm_data)) > 0:\n",
    "                mean_value = np.nanmean(vrm_data)\n",
    "                print(f\"Filling NaNs with the mean: {mean_value}\")\n",
    "                vrm_data = np.nan_to_num(vrm_data, nan=mean_value)\n",
    "            else:\n",
    "                print(f\"All values are NaN in {file_path}. Skipping this file.\")\n",
    "                return None  # Skip this file if all values are NaN\n",
    "        \n",
    "        scaler = MinMaxScaler()\n",
    "        vrm_data_scaled = scaler.fit_transform(vrm_data)\n",
    "        return vrm_data_scaled\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def fourier_transform(data):\n",
    "    fft_data = np.fft.fft(data)\n",
    "    fft_data = np.abs(fft_data)\n",
    "    return fft_data\n",
    "\n",
    "folder_path = 'testing_data_trial_2'\n",
    "\n",
    "processed_data = []\n",
    "file_names = []\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('.csv'):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        data = preprocess_csv(file_path)\n",
    "        if data is not None:\n",
    "            processed_data.append(data)\n",
    "            file_names.append(filename)\n",
    "\n",
    "\n",
    "# Preparing Data for LSTM\n",
    "sequence_length = 20\n",
    "X = []\n",
    "for data in processed_data:\n",
    "    for i in range(len(data) - sequence_length + 1):\n",
    "        X.append(data[i:i + sequence_length])\n",
    "\n",
    "# Convert to NumPy array and reshape\n",
    "X = np.array(X)\n",
    "X = X.reshape(X.shape[0], sequence_length, 1)  # Reshape to (number_of_samples, sequence_length, num_features)\n",
    "\n",
    "# Check for NaN values in X\n",
    "if np.any(np.isnan(X)):\n",
    "    print(\"NaN values found in X. Exiting.\")\n",
    "    exit()\n",
    "\n",
    "# Create a more complex LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, return_sequences=True, input_shape=(sequence_length, 1)))  # First LSTM layer\n",
    "model.add(Dropout(0.2))  # Dropout layer to prevent overfitting\n",
    "model.add(LSTM(50, return_sequences=True))  # Second LSTM layer\n",
    "model.add(Dropout(0.2))  # Another Dropout layer\n",
    "model.add(LSTM(25))  # Third LSTM layer\n",
    "model.add(Dropout(0.2))  # Dropout layer\n",
    "model.add(Dense(1))  # Output layer\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X, X, epochs=20, batch_size=32)  # Increased epochs for better training\n",
    "\n",
    "# Predict LSTM features\n",
    "lstm_features = model.predict(X)\n",
    "lstm_features = lstm_features.reshape(lstm_features.shape[0], -1)\n",
    "fourier_features = [fourier_transform(data.flatten()) for data in processed_data]\n",
    "\n",
    "# Combine features for clustering\n",
    "combined_features = []\n",
    "for lstm_f, fourier_f in zip(lstm_features, fourier_features):\n",
    "    combined_features.append(np.concatenate((lstm_f, fourier_f[:10])))\n",
    "\n",
    "# KMeans clustering\n",
    "kmeans = KMeans(n_clusters=12, random_state=0)\n",
    "kmeans.fit(combined_features)\n",
    "labels = kmeans.labels_\n",
    "\n",
    "# Create directories for clusters\n",
    "os.makedirs('Signature Fault Clusters Version 4 Sequencial to 20/VRM', exist_ok=True)\n",
    "for i in range(12):\n",
    "    os.makedirs(os.path.join('Signature Fault Clusters Version 4 Sequencial to 20/VRM', f'VRM Cluster {i}'), exist_ok=True)\n",
    "\n",
    "# Move files to their respective clusters\n",
    "for i, filename in enumerate(file_names):\n",
    "    cluster_label = labels[i]\n",
    "    source_path = os.path.join(folder_path, filename)\n",
    "    destination_path = os.path.join('Signature Fault Clusters Version 4 Sequencial to 20/VRM', f'VRM Cluster {cluster_label}', filename)\n",
    "    os.rename(source_path, destination_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59649c34-2e6c-49c1-9265-ac715125abcf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
