{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea19e76-ed3d-4281-b93e-bf030a19c6c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91702\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m72470/72470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1152s\u001b[0m 16ms/step - loss: 0.0099\n",
      "Epoch 2/20\n",
      "\u001b[1m36415/72470\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m9:21\u001b[0m 16ms/step - loss: 0.0084"
     ]
    }
   ],
   "source": [
    "# Added more layers in LTSM Models for Good Results with Dense etc.,\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras._tf_keras.keras.models import Sequential \n",
    "from keras._tf_keras.keras.layers import Dense, LSTM, Dropout\n",
    "\n",
    "def preprocess_csv(file_path):\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        vrm_data = df['VRM'].values.reshape(-1, 1)\n",
    "        \n",
    "        # Check for NaN values\n",
    "        if np.any(np.isnan(vrm_data)):\n",
    "            print(f\"NaN values found in {file_path}.\")\n",
    "            # Check if there are any valid values to compute the mean\n",
    "            if np.count_nonzero(~np.isnan(vrm_data)) > 0:\n",
    "                mean_value = np.nanmean(vrm_data)\n",
    "                print(f\"Filling NaNs with the mean: {mean_value}\")\n",
    "                vrm_data = np.nan_to_num(vrm_data, nan=mean_value)\n",
    "            else:\n",
    "                print(f\"All values are NaN in {file_path}. Skipping this file.\")\n",
    "                return None  # Skip this file if all values are NaN\n",
    "        \n",
    "        scaler = MinMaxScaler()\n",
    "        vrm_data_scaled = scaler.fit_transform(vrm_data)\n",
    "        return vrm_data_scaled\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def fourier_transform(data):\n",
    "    fft_data = np.fft.fft(data)\n",
    "    fft_data = np.abs(fft_data)\n",
    "    return fft_data\n",
    "\n",
    "folder_path = 'VRM'\n",
    "\n",
    "processed_data = []\n",
    "file_names = []\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('.csv'):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        data = preprocess_csv(file_path)\n",
    "        if data is not None:\n",
    "            processed_data.append(data)\n",
    "            file_names.append(filename)\n",
    "\n",
    "\n",
    "\n",
    "sequence_length = 20\n",
    "# Preparing Data for LSTM\n",
    "sequence_length = 20\n",
    "X = []\n",
    "for data in processed_data:\n",
    "    for i in range(len(data) - sequence_length + 1):\n",
    "        X.append(data[i:i + sequence_length])\n",
    "\n",
    "# Convert to NumPy array and reshape\n",
    "X = np.array(X)\n",
    "X = X.reshape(X.shape[0], sequence_length, 1)  # Reshape to (number_of_samples, sequence_length, num_features)\n",
    "\n",
    "# Check for NaN values in X\n",
    "if np.any(np.isnan(X)):\n",
    "    print(\"NaN values found in X. Exiting.\")\n",
    "    exit()\n",
    "\n",
    "# Create a more complex LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, return_sequences=True, input_shape=(sequence_length, 1)))  # First LSTM layer\n",
    "model.add(Dropout(0.2))  # Dropout layer to prevent overfitting\n",
    "model.add(LSTM(50, return_sequences=True))  # Second LSTM layer\n",
    "model.add(Dropout(0.2))  # Another Dropout layer\n",
    "model.add(LSTM(25))  # Third LSTM layer\n",
    "model.add(Dropout(0.2))  # Dropout layer\n",
    "model.add(Dense(1))  # Output layer\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X, X, epochs=20, batch_size=32)  # Increased epochs for better training\n",
    "\n",
    "# Predict LSTM features\n",
    "lstm_features = model.predict(X)\n",
    "lstm_features = lstm_features.reshape(lstm_features.shape[0], -1)\n",
    "fourier_features = [fourier_transform(data.flatten()) for data in processed_data]\n",
    "\n",
    "# Combine features for clustering\n",
    "combined_features = []\n",
    "for lstm_f, fourier_f in zip(lstm_features, fourier_features):\n",
    "    combined_features.append(np.concatenate((lstm_f, fourier_f[:10])))\n",
    "\n",
    "# KMeans clustering\n",
    "kmeans = KMeans(n_clusters=12, random_state=0)\n",
    "kmeans.fit(combined_features)\n",
    "labels = kmeans.labels_\n",
    "\n",
    "# Create directories for clusters\n",
    "os.makedirs('Signature Fault Clusters Version 3/VRM', exist_ok=True)\n",
    "for i in range(12):\n",
    "    os.makedirs(os.path.join('Signature Fault Clusters Version 3/VRM', f'VRM Cluster {i}'), exist_ok=True)\n",
    "\n",
    "# Move files to their respective clusters\n",
    "for i, filename in enumerate(file_names):\n",
    "    cluster_label = labels[i]\n",
    "    source_path = os.path.join(folder_path, filename)\n",
    "    destination_path = os.path.join('Signature Fault Clusters Version 3/VRM', f'VRM Cluster {cluster_label}', filename)\n",
    "    os.rename(source_path, destination_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59649c34-2e6c-49c1-9265-ac715125abcf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
