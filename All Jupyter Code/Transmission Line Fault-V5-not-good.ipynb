{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4290d861-1836-4c22-9d02-55bdeca9d492",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\College\\7th Semester\\Internship\\Application\\venv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.fft import fft, fftfreq\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "# 1. Data Loading and Preprocessing\n",
    "def load_and_preprocess_data(folder_path):\n",
    "    all_data = []\n",
    "    filenames = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".csv\"):\n",
    "            try:\n",
    "                df = pd.read_csv(os.path.join(folder_path, filename))\n",
    "                # Assuming 'VRM' column contains the fault voltage data\n",
    "                if 'VRM' in df.columns:  \n",
    "                    vrm_data = df['VRM'].values\n",
    "                    # Noise Reduction (Simple Moving Average) - adjust window as needed\n",
    "                    window_size = 5  \n",
    "                    vrm_data = np.convolve(vrm_data, np.ones(window_size), 'valid') / window_size\n",
    "\n",
    "                    # Feature extraction\n",
    "                    features = {\n",
    "                      'mean': np.mean(vrm_data),\n",
    "                      'std': np.std(vrm_data),\n",
    "                      'variance': np.var(vrm_data),\n",
    "                    }\n",
    "                    \n",
    "                    # Fourier Transformation\n",
    "                    N = len(vrm_data)\n",
    "                    yf = fft(vrm_data)\n",
    "                    xf = fftfreq(N, 1)  # Assuming a sampling rate of 1\n",
    "                    dominant_frequency_index = np.argmax(np.abs(yf[1:N//2])) + 1 #Ignore DC component\n",
    "                    features['dominant_frequency'] = xf[dominant_frequency_index]\n",
    "\n",
    "                    all_data.append(list(features.values()))\n",
    "                    filenames.append(filename)\n",
    "                else:\n",
    "                    print(f\"Warning: 'VRM' column not found in {filename}. Skipping.\")\n",
    "            except pd.errors.ParserError:\n",
    "                print(f\"Warning: Could not parse {filename}. Skipping.\")\n",
    "\n",
    "    return np.array(all_data), filenames\n",
    "\n",
    "# 2. LSTM Feature Engineering (Optional, if you want to use LSTM features)\n",
    "def extract_lstm_features(data):\n",
    "    #Reshape data\n",
    "    X = np.array(data).reshape(len(data), 1, len(data[0]))\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(50, activation='relu', input_shape=(1, len(data[0]))))  # Adjust input_shape\n",
    "    model.add(Dense(len(data[0])))  # Output size matches input features\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    model.fit(X, X, epochs=10, verbose=0)  # Train on the same data to get LSTM representations\n",
    "    lstm_features = model.predict(X)\n",
    "    return lstm_features.reshape(len(data), len(data[0]))\n",
    "\n",
    "# 3. Clustering\n",
    "def perform_clustering(data, n_clusters=10):\n",
    "    scaler = StandardScaler()\n",
    "    scaled_data = scaler.fit_transform(data)\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=0)\n",
    "    clusters = kmeans.fit_predict(scaled_data)\n",
    "    return clusters\n",
    "\n",
    "# 4. Organize Files\n",
    "def organize_files(folder_path, filenames, clusters):\n",
    "    for i, cluster_label in enumerate(clusters):\n",
    "        cluster_folder = os.path.join(folder_path, f\"cluster_{cluster_label}\")\n",
    "        os.makedirs(cluster_folder, exist_ok=True)\n",
    "        source_file = os.path.join(folder_path, filenames[i])\n",
    "        destination_file = os.path.join(cluster_folder, filenames[i])\n",
    "        os.rename(source_file, destination_file)\n",
    "\n",
    "# Main execution\n",
    "folder_path = 'testing_data_trial_2_with_features'  # Replace with the actual folder path\n",
    "data, filenames = load_and_preprocess_data(folder_path)\n",
    "\n",
    "#Optional LSTM Feature extraction. Comment out if not needed.\n",
    "lstm_data = extract_lstm_features(data)\n",
    "clusters = perform_clustering(lstm_data)\n",
    "\n",
    "clusters = perform_clustering(data)\n",
    "organize_files(folder_path, filenames, clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f632135-cb25-4686-8817-9db2182a79d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f89db8-cfd5-4d5c-9679-95f6ceddf632",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
